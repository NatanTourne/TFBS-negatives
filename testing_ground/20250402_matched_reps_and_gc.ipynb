{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import h5torch\n",
    "import py2bit\n",
    "from tqdm import tqdm\n",
    "from tqdm import trange\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the H5torch file in read mode\n",
    "h5t_file = \"/data/home/natant/Negatives/testing_ground/20250402_test.h5t\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing file: /data/home/natant/Negatives/testing_ground/20250404_temp/MCF-7.h5t\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 4102/20998 [00:11<00:46, 365.59it/s]\n",
      " 20%|██        | 1/5 [00:11<00:44, 11.23s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 34\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m tqdm(pos_indices):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mchr\u001b[39m \u001b[38;5;241m=\u001b[39m f[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1/peak_ix_to_chr\u001b[39m\u001b[38;5;124m\"\u001b[39m][:][j]\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mstr\u001b[39m)\n\u001b[0;32m---> 34\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m1/peak_ix_to_pos\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m[j]\n\u001b[1;32m     35\u001b[0m     start \u001b[38;5;241m=\u001b[39m pos \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[1;32m     36\u001b[0m     end \u001b[38;5;241m=\u001b[39m pos \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m51\u001b[39m\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/opt/Anaconda3/envs/plmbind4/lib/python3.11/site-packages/h5py/_hl/dataset.py:758\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[0;34m(self, args, new_dtype)\u001b[0m\n\u001b[1;32m    756\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fast_read_ok \u001b[38;5;129;01mand\u001b[39;00m (new_dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 758\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fast_reader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    759\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    760\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m  \u001b[38;5;66;03m# Fall back to Python read pathway below\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# temp func ins\n",
    "h5t_loc = \"/data/home/natant/Negatives/testing_ground/20250404_temp\"\n",
    "out_folder = \"/data/home/natant/Negatives/testing_ground/20250404_temp\"\n",
    "\n",
    "\n",
    "if not os.path.exists(h5t_loc):\n",
    "    raise FileNotFoundError(f\"The folder {h5t_loc} does not exist.\")\n",
    "\n",
    "h5t_files = [os.path.join(h5t_loc, file) for file in os.listdir(h5t_loc) if file.endswith(\".h5t\")]\n",
    "\n",
    "for h5t_file in h5t_files:\n",
    "    celltype = os.path.splitext(os.path.basename(h5t_file))[0]\n",
    "    print(f\"Processing file: {h5t_file}\")\n",
    "    with h5torch.File(h5t_file, \"r\") as f:\n",
    "        genome = {k : f[\"unstructured\"][k] for k in list(f[\"unstructured\"]) if k.startswith(\"chr\")}\n",
    "\n",
    "        prot_names = [name.decode(\"utf-8\") for name in f[\"0/prot_names\"]]\n",
    "        if \"ATAC_peak\" not in prot_names:\n",
    "            raise ValueError(\"ATAC_peak not found in prot_names.\")\n",
    "\n",
    "        # Exclude \"ATAC_peak\" explicitly\n",
    "        for i, TF in enumerate(tqdm(prot_names)):\n",
    "            if TF == \"ATAC_peak\":\n",
    "                continue  # Skip ATAC_peak\n",
    "\n",
    "            index = i\n",
    "            pos_indices = np.where(f[\"central\"][index, :] == 1)[0]\n",
    "\n",
    "            # Write the positive sequences to a BED file\n",
    "            output_path = os.path.join(out_folder, f\"{celltype}_{TF}_positives.bed\")\n",
    "            with open(output_path, \"w\") as bed_file:\n",
    "                for j in tqdm(pos_indices):\n",
    "                    chr = f[\"1/peak_ix_to_chr\"][:][j].astype(str)\n",
    "                    pos = f[\"1/peak_ix_to_pos\"][:][j]\n",
    "                    start = pos - 50\n",
    "                    end = pos + 51\n",
    "                    bed_file.write(f\"{chr}\\t{start}\\t{end}\\t{TF}\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "chr1    101\n",
       "chr1    101\n",
       "chr1    101\n",
       "chr1    101\n",
       "chr1    101\n",
       "       ... \n",
       "chrX    101\n",
       "chrX    101\n",
       "chrX    101\n",
       "chrX    101\n",
       "chrY    101\n",
       "Length: 6588, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "library(gkmSVM)\n",
    "library(BSgenome.Hsapiens.UCSC.hg38.masked)\n",
    "input_folder <- \"/data/home/natant/Negatives/testing_ground/20250404_temp/\"\n",
    "output_folder <- \"/data/home/natant/Negatives/testing_ground/20250404_temp/\"\n",
    "bed_files <- list.files(input_folder, pattern = \"\\\\.bed$\", full.names = TRUE)\n",
    "for (input_bed in bed_files) {\n",
    "    output_bed <- file.path(output_folder, paste0(gsub(\"_positive_sequences$\", \"\", tools::file_path_sans_ext(basename(input_bed))), \"_negatives.bed\"))\n",
    "    genNullSeqs(input_bed, genome = BSgenome.Hsapiens.UCSC.hg38.masked, outputBedFN = output_bed, nMaxTrials = 10, xfold = 1)\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for negative bed files for cell type: MCF-7\n",
      "Checking for negative bed files for cell type: IMR90\n",
      "Processing negative bed file: /data/home/natant/Negatives/testing_ground/20250404_temp/IMR90_MafK_(ab50322)_negatives.bed\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot convert the series to <class 'int'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m     chromosomes \u001b[38;5;241m=\u001b[39m temp_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchromosome\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     22\u001b[0m     centers \u001b[38;5;241m=\u001b[39m ((temp_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m temp_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mend\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m---> 23\u001b[0m     lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mint\u001b[39m(temp_file[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# for line in bed_file:\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;66;03m#     parts = line.strip().split(\"\\t\")\u001b[39;00m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m#     if len(parts) < 3:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m#     centers.append((start + end) // 2)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m#     lengths.append(end - start)\u001b[39;00m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChromosomes: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchromosomes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/Anaconda3/envs/plmbind4/lib/python3.11/site-packages/pandas/core/series.py:248\u001b[0m, in \u001b[0;36m_coerce_method.<locals>.wrapper\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCalling \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m on a single element Series is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will raise a TypeError in the future. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    245\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    246\u001b[0m     )\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m converter(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 248\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot convert the series to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconverter\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot convert the series to <class 'int'>"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# The bed files with the negative samples have the following naming scheme: # {celltype}_{TF}_negatives.bed\n",
    "negative_bed_files = [file for file in os.listdir(out_folder) if file.endswith(\"_negatives.bed\")]\n",
    "\n",
    "for h5t_file in h5t_files:\n",
    "    celltype = os.path.splitext(os.path.basename(h5t_file))[0]\n",
    "    print(f\"Checking for negative bed files for cell type: {celltype}\")\n",
    "    \n",
    "    matching_files = [file for file in negative_bed_files if file.startswith(celltype)]\n",
    "    for bed_file_name in matching_files:\n",
    "        bed_file_path = os.path.join(out_folder, bed_file_name)\n",
    "        print(f\"Processing negative bed file: {bed_file_path}\")\n",
    "        \n",
    "        chromosomes = []\n",
    "        centers = []\n",
    "        lengths = []\n",
    "        \n",
    "        with open(bed_file_path, \"r\") as bed_file:\n",
    "            temp_file = pd.read_csv(bed_file_path, sep=\"\\t\", header=None, names=[\"chromosome\", \"start\", \"end\"])\n",
    "            chromosomes = temp_file[\"chromosome\"].tolist()\n",
    "            #! filter out the special chromosomes??????? I think it's quite a large precentage....? Should I just keep them in?\n",
    "            centers = ((temp_file[\"start\"] + temp_file[\"end\"]) // 2).tolist()\n",
    "            lengths = (temp_file[\"end\"] - temp_file[\"start\"]).tolist() #! the weird R script returns 100bp negatives for 101bp positives for some reason??????\n",
    "            \n",
    "            with h5torch.File(h5t_file, \"a\") as f:   \n",
    "                f.register(\n",
    "                    np.stack(centers),\n",
    "                    axis=\"unstructured\",\n",
    "                    name=f\"sampled_negs_{TF}_pos\",\n",
    "                    mode=\"N-D\",\n",
    "                    dtype_save=\"int8\",\n",
    "                    dtype_load=\"int8\",\n",
    "                )\n",
    "                f.register(\n",
    "                    np.array(chromosomes).astype(bytes),\n",
    "                    axis=\"unstructured\",\n",
    "                    name=f\"sampled_negs_{TF}_chr\",\n",
    "                    mode=\"N-D\",\n",
    "                    dtype_save=\"bytes\",\n",
    "                    dtype_load=\"str\",\n",
    "                )\n",
    "                f.register(\n",
    "                    np.array(lengths),\n",
    "                    axis=\"unstructured\",\n",
    "                    name=f\"sampled_negs_{TF}_len\",\n",
    "                    mode=\"N-D\",\n",
    "                    dtype_save=\"int8\",\n",
    "                    dtype_load=\"int8\",\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        100\n",
       "1        100\n",
       "2        100\n",
       "3        100\n",
       "4        100\n",
       "        ... \n",
       "39758    100\n",
       "39759    100\n",
       "39760    100\n",
       "39761    100\n",
       "39762    100\n",
       "Length: 39763, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_file[\"end\"] - temp_file[\"start\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'20250402_test_longer'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.splitext(os.path.basename(h5t_file))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'TAATCTATAAAGTACTCTTACAAGTCCATATTGCCCAATAAATAAATAAGCAGTGGATATGAACAGGCTGTTCATATAGAAAGAAATTCCAACAAACACAT'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\".join([rev_mapping[l] for l in DNA_region_pos])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ATAC_peak',\n",
       " 'CTCF',\n",
       " 'YY1_(SC-281)',\n",
       " 'CREB1_(SC-240)',\n",
       " 'Max',\n",
       " 'TCF12',\n",
       " 'FOSL2',\n",
       " 'ELF1_(SC-631)',\n",
       " 'BHLHE40',\n",
       " 'ATF3',\n",
       " 'USF-1',\n",
       " 'ETS1',\n",
       " 'SIX5',\n",
       " 'ZBTB33',\n",
       " 'FOXA1_(SC-101058)']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prot_names"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plmbind4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
