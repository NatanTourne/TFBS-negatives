{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32ce49a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/anaconda3/envs/Negs/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5torch\n",
    "import numpy as np\n",
    "from pyjaspar import jaspardb\n",
    "import pandas as pd\n",
    "from Bio.Seq import Seq\n",
    "from TFBS_negatives.data import HQ_dataset\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "import pandas as pd\n",
    "\n",
    "out_folder = \"/data/home/natant/Negatives/Runs/full_run_1/motifs_TEST\"\n",
    "data_folder = \"/data/home/natant/Negatives/Data/Encode690/ENCODE_hg38_subset_101bp_celltypes_ATAC_H5_all_chr copy/\"\n",
    "h5t_files = [f for f in os.listdir(data_folder) if f.endswith('.h5t')]\n",
    "prot_names = []\n",
    "for h5t_file in h5t_files:\n",
    "    file_path = os.path.join(data_folder, h5t_file)\n",
    "    file = h5torch.File(file_path, 'r')\n",
    "    \n",
    "    prot_names.extend(file[\"0/prot_names\"][:].astype(str).tolist())\n",
    "\n",
    "unique_tfs = np.unique(prot_names)\n",
    "unique_tfs = unique_tfs[unique_tfs != \"ATAC_peak\"]\n",
    "\n",
    "jaspar_connection = \"\"\"ARID3A_(NB100-279):\n",
    "ATF1_(06-325):\n",
    "ATF2_(SC-81188): MA1632.1 MA1632.2\n",
    "ATF3: MA0605.2 MA0605.3\n",
    "BHLHE40: MA0464.2 MA0464.3\n",
    "Bach1_(sc-14700): MA1633.1 MA1633.2\n",
    "CEBPB_(SC-150): MA0466.1 MA0466.2 MA0466.3 MA0466.4\n",
    "CEBPD_(SC-636): MA0836.1 MA0836.2 MA0836.3\n",
    "CREB1_(SC-240): MA0018.1 MA0018.2 MA0018.3 MA0018.4 MA0018.5\n",
    "CTCF: MA0139.1 MA0139.2 MA1929.1 MA1929.2 MA1930.1 MA1930.2\n",
    "ELF1_(SC-631): MA0473.1 MA0473.2 MA0473.3 MA0473.4\n",
    "ELK1_(1277-1): MA0028.1 MA0028.2 MA0028.3\n",
    "ETS1: MA0098.1 MA0098.3 MA0098.4\n",
    "Egr-1: MA0162.2 MA0162.3 MA0162.4 MA0162.5\n",
    "FOSL1_(SC-183): MA0477.1 MA0477.2 MA0477.3\n",
    "FOSL2: MA0478.1 MA0478.2\n",
    "FOXA1_(SC-101058): MA0148.1 MA0148.2 MA0148.3 MA0148.4 MA0148.5\n",
    "FOXM1_(SC-502): UN0802.1\n",
    "GATA3_(SC-268): MA0037.1 MA0037.2 MA0037.3\n",
    "HSF1: MA0486.1 MA0486.2\n",
    "IKZF1_(IkN)_(UCLA): MA1508.1 MA1508.2\n",
    "IRF3: MA1418.1 MA1418.2\n",
    "JunD: MA0491.1 MA0491.2 MA0491.3 MA0492.1 MA0492.2\n",
    "MAZ_(ab85725): MA1522.1 MA1522.2\n",
    "MEF2A: MA0052.1 MA0052.2 MA0052.3 MA0052.4 MA0052.5\n",
    "MYBL2_(SC-81192): MA0777.1\n",
    "MafF_(M8194): MA0495.1 MA0495.2 MA0495.3 MA0495.4\n",
    "MafK_(ab50322): MA0496.1 MA0496.2 MA0496.3 MA0496.4\n",
    "Max: MA0058.1 MA0058.2 MA0058.3 MA0058.4\n",
    "Mxi1_(AF4185): MA1108.1 MA1108.2 MA1108.3\n",
    "NF-YA: MA0060.1 MA0060.2 MA0060.3 MA0060.4\n",
    "NF-YB: MA0502.1 MA0502.2 MA0502.3\n",
    "NFIC_(SC-81335): MA0161.1 MA0161.2 MA0161.3 MA1527.1 MA1527.2\n",
    "NR2F2_(SC-271940): MA1111.1 MA1111.2\n",
    "Nrf1: MA0506.1\n",
    "Pbx3: MA1114.1 MA1114.2\n",
    "RFX5_(200-401-194): MA0510.1 MA0510.2 MA0510.3\n",
    "RXRA:\n",
    "SETDB1:\n",
    "SIX5:\n",
    "SP1: MA0079.1 MA0079.2 MA0079.3 MA0079.4 MA0079.5\n",
    "SRF: MA0083.1 MA0083.2 MA0083.3\n",
    "STAT5A_(SC-74442):\n",
    "TBP:\n",
    "TCF12: MA1648.1 MA1648.2\n",
    "TCF7L2: MA0523.1 MA0523.2\n",
    "TEAD4_(SC-101184): MA0809.1 MA0809.2 MA0809.3\n",
    "USF-1:\n",
    "USF2: MA0526.1 MA0526.2 MA0526.3 MA0526.4 MA0526.5\n",
    "YY1_(SC-281): MA0095.1 MA0095.2\n",
    "ZBTB33: MA0527.1 MA0527.2\n",
    "ZBTB7A_(SC-34508): MA0750.1 MA0750.2 MA0750.3\n",
    "ZEB1_(SC-25388): MA0103.2 MA0103.3 MA0103.4\n",
    "ZNF217:\n",
    "ZNF274: MA1592.1 MA1592.2\n",
    "ZZZ3:\n",
    "Znf143_(16618-1-AP): MA0088.2\n",
    "\"\"\"\n",
    "jaspar_dict = {}\n",
    "for line in jaspar_connection.strip().split(\"\\n\"):\n",
    "    if \":\" in line:\n",
    "        tf, matrices = line.split(\":\", 1)\n",
    "        jaspar_dict[tf.strip()] = matrices.strip().split() if matrices.strip() else []\n",
    "\n",
    "matrix_ids = [value for values in jaspar_dict.values() for value in values]\n",
    "\n",
    "jdb_obj = jaspardb(release='JASPAR2024')\n",
    "motif_objects = {}\n",
    "for mid in matrix_ids:\n",
    "    motif = jdb_obj.fetch_motif_by_id(mid)\n",
    "    motif.pseudocounts = 0.8\n",
    "    pssm = motif.pssm  # compute the position-specific scoring matrix (PSSM)\n",
    "    motif_objects[mid] = pssm\n",
    "\n",
    "part1 =  ['chr13', 'chr13_KI270838v1_alt', 'chr13_KI270839v1_alt', 'chr13_KI270840v1_alt', 'chr13_KI270841v1_alt', 'chr13_KI270842v1_alt', 'chr13_KI270843v1_alt', 'chr18', 'chr18_GL383567v1_alt', 'chr18_GL383568v1_alt', 'chr18_GL383569v1_alt', 'chr18_GL383570v1_alt', 'chr18_GL383571v1_alt', 'chr18_GL383572v1_alt', 'chr18_KI270863v1_alt', 'chr18_KI270864v1_alt', 'chr18_KI270911v1_alt', 'chr18_KI270912v1_alt', 'chr19', 'chr19_GL000209v2_alt', 'chr19_GL383573v1_alt', 'chr19_GL383574v1_alt', 'chr19_GL383575v2_alt', 'chr19_GL383576v1_alt', 'chr19_GL949746v1_alt', 'chr19_GL949747v2_alt', 'chr19_GL949748v2_alt', 'chr19_GL949749v2_alt', 'chr19_GL949750v2_alt', 'chr19_GL949751v2_alt', 'chr19_GL949752v1_alt', 'chr19_GL949753v2_alt', 'chr19_KI270865v1_alt', 'chr19_KI270866v1_alt', 'chr19_KI270867v1_alt', 'chr19_KI270868v1_alt', 'chr19_KI270882v1_alt', 'chr19_KI270883v1_alt', 'chr19_KI270884v1_alt', 'chr19_KI270885v1_alt', 'chr19_KI270886v1_alt', 'chr19_KI270887v1_alt', 'chr19_KI270888v1_alt', 'chr19_KI270889v1_alt', 'chr19_KI270890v1_alt', 'chr19_KI270891v1_alt', 'chr19_KI270914v1_alt', 'chr19_KI270915v1_alt', 'chr19_KI270916v1_alt', 'chr19_KI270917v1_alt', 'chr19_KI270918v1_alt', 'chr19_KI270919v1_alt', 'chr19_KI270920v1_alt', 'chr19_KI270921v1_alt', 'chr19_KI270922v1_alt', 'chr19_KI270923v1_alt', 'chr19_KI270929v1_alt', 'chr19_KI270930v1_alt', 'chr19_KI270931v1_alt', 'chr19_KI270932v1_alt', 'chr19_KI270933v1_alt', 'chr19_KI270938v1_alt', 'chr20', 'chr20_GL383577v2_alt', 'chr20_KI270869v1_alt', 'chr20_KI270870v1_alt', 'chr20_KI270871v1_alt', 'chr3', 'chr3_GL000221v1_random', 'chr3_GL383526v1_alt', 'chr3_JH636055v2_alt', 'chr3_KI270777v1_alt', 'chr3_KI270778v1_alt', 'chr3_KI270779v1_alt', 'chr3_KI270780v1_alt', 'chr3_KI270781v1_alt', 'chr3_KI270782v1_alt', 'chr3_KI270783v1_alt', 'chr3_KI270784v1_alt', 'chr3_KI270895v1_alt', 'chr3_KI270924v1_alt', 'chr3_KI270934v1_alt', 'chr3_KI270935v1_alt', 'chr3_KI270936v1_alt', 'chr3_KI270937v1_alt', 'chr4', 'chr4_GL000008v2_random', 'chr4_GL000257v2_alt', 'chr4_GL383527v1_alt', 'chr4_GL383528v1_alt', 'chr4_KI270785v1_alt', 'chr4_KI270786v1_alt', 'chr4_KI270787v1_alt', 'chr4_KI270788v1_alt', 'chr4_KI270789v1_alt', 'chr4_KI270790v1_alt', 'chr4_KI270896v1_alt', 'chr4_KI270925v1_alt', 'chr7', 'chr7_GL383534v2_alt', 'chr7_KI270803v1_alt', 'chr7_KI270804v1_alt', 'chr7_KI270805v1_alt', 'chr7_KI270806v1_alt', 'chr7_KI270807v1_alt', 'chr7_KI270808v1_alt', 'chr7_KI270809v1_alt', 'chr7_KI270899v1_alt', 'chrX', 'chrX_KI270880v1_alt', 'chrX_KI270881v1_alt', 'chrX_KI270913v1_alt']\n",
    "part2 = ['chr1', 'chr10', 'chr10_GL383545v1_alt', 'chr10_GL383546v1_alt', 'chr10_KI270824v1_alt', 'chr10_KI270825v1_alt', 'chr11', 'chr11_GL383547v1_alt', 'chr11_JH159136v1_alt', 'chr11_JH159137v1_alt', 'chr11_KI270721v1_random', 'chr11_KI270826v1_alt', 'chr11_KI270827v1_alt', 'chr11_KI270829v1_alt', 'chr11_KI270830v1_alt', 'chr11_KI270831v1_alt', 'chr11_KI270832v1_alt', 'chr11_KI270902v1_alt', 'chr11_KI270903v1_alt', 'chr11_KI270927v1_alt', 'chr15', 'chr15_GL383554v1_alt', 'chr15_GL383555v2_alt', 'chr15_KI270727v1_random', 'chr15_KI270848v1_alt', 'chr15_KI270849v1_alt', 'chr15_KI270850v1_alt', 'chr15_KI270851v1_alt', 'chr15_KI270852v1_alt', 'chr15_KI270905v1_alt', 'chr15_KI270906v1_alt', 'chr1_GL383518v1_alt', 'chr1_GL383519v1_alt', 'chr1_GL383520v2_alt', 'chr1_KI270706v1_random', 'chr1_KI270707v1_random', 'chr1_KI270708v1_random', 'chr1_KI270709v1_random', 'chr1_KI270710v1_random', 'chr1_KI270711v1_random', 'chr1_KI270712v1_random', 'chr1_KI270713v1_random', 'chr1_KI270714v1_random', 'chr1_KI270759v1_alt', 'chr1_KI270760v1_alt', 'chr1_KI270761v1_alt', 'chr1_KI270762v1_alt', 'chr1_KI270763v1_alt', 'chr1_KI270764v1_alt', 'chr1_KI270765v1_alt', 'chr1_KI270766v1_alt', 'chr1_KI270892v1_alt', 'chr21', 'chr21_GL383578v2_alt', 'chr21_GL383579v2_alt', 'chr21_GL383580v2_alt', 'chr21_GL383581v2_alt', 'chr21_KI270872v1_alt', 'chr21_KI270873v1_alt', 'chr21_KI270874v1_alt', 'chr22', 'chr22_GL383582v2_alt', 'chr22_GL383583v2_alt', 'chr22_KB663609v1_alt', 'chr22_KI270731v1_random', 'chr22_KI270732v1_random', 'chr22_KI270733v1_random', 'chr22_KI270734v1_random', 'chr22_KI270735v1_random', 'chr22_KI270736v1_random', 'chr22_KI270737v1_random', 'chr22_KI270738v1_random', 'chr22_KI270739v1_random', 'chr22_KI270875v1_alt', 'chr22_KI270876v1_alt', 'chr22_KI270877v1_alt', 'chr22_KI270878v1_alt', 'chr22_KI270879v1_alt', 'chr22_KI270928v1_alt', 'chr9', 'chr9_GL383539v1_alt', 'chr9_GL383540v1_alt', 'chr9_GL383541v1_alt', 'chr9_GL383542v1_alt', 'chr9_KI270717v1_random', 'chr9_KI270718v1_random', 'chr9_KI270719v1_random', 'chr9_KI270720v1_random', 'chr9_KI270823v1_alt', 'chrY', 'chrY_KI270740v1_random']\n",
    "part3 = ['chr12', 'chr12_GL383549v1_alt', 'chr12_GL383550v2_alt', 'chr12_GL383551v1_alt', 'chr12_GL383552v1_alt', 'chr12_GL383553v2_alt', 'chr12_GL877875v1_alt', 'chr12_GL877876v1_alt', 'chr12_KI270833v1_alt', 'chr12_KI270834v1_alt', 'chr12_KI270835v1_alt', 'chr12_KI270836v1_alt', 'chr12_KI270837v1_alt', 'chr12_KI270904v1_alt', 'chr14', 'chr14_GL000009v2_random', 'chr14_GL000194v1_random', 'chr14_GL000225v1_random', 'chr14_KI270722v1_random', 'chr14_KI270723v1_random', 'chr14_KI270724v1_random', 'chr14_KI270725v1_random', 'chr14_KI270726v1_random', 'chr14_KI270844v1_alt', 'chr14_KI270845v1_alt', 'chr14_KI270846v1_alt', 'chr14_KI270847v1_alt', 'chr16', 'chr16_GL383556v1_alt', 'chr16_GL383557v1_alt', 'chr16_KI270728v1_random', 'chr16_KI270853v1_alt', 'chr16_KI270854v1_alt', 'chr16_KI270855v1_alt', 'chr16_KI270856v1_alt', 'chr17', 'chr17_GL000205v2_random', 'chr17_GL000258v2_alt', 'chr17_GL383563v3_alt', 'chr17_GL383564v2_alt', 'chr17_GL383565v1_alt', 'chr17_GL383566v1_alt', 'chr17_JH159146v1_alt', 'chr17_JH159147v1_alt', 'chr17_JH159148v1_alt', 'chr17_KI270729v1_random', 'chr17_KI270730v1_random', 'chr17_KI270857v1_alt', 'chr17_KI270858v1_alt', 'chr17_KI270859v1_alt', 'chr17_KI270860v1_alt', 'chr17_KI270861v1_alt', 'chr17_KI270862v1_alt', 'chr17_KI270907v1_alt', 'chr17_KI270908v1_alt', 'chr17_KI270909v1_alt', 'chr17_KI270910v1_alt', 'chr2', 'chr2_GL383521v1_alt', 'chr2_GL383522v1_alt', 'chr2_GL582966v2_alt', 'chr2_KI270715v1_random', 'chr2_KI270716v1_random', 'chr2_KI270767v1_alt', 'chr2_KI270768v1_alt', 'chr2_KI270769v1_alt', 'chr2_KI270770v1_alt', 'chr2_KI270771v1_alt', 'chr2_KI270772v1_alt', 'chr2_KI270773v1_alt', 'chr2_KI270774v1_alt', 'chr2_KI270775v1_alt', 'chr2_KI270776v1_alt', 'chr2_KI270893v1_alt', 'chr2_KI270894v1_alt', 'chr5', 'chr5_GL000208v1_random', 'chr5_GL339449v2_alt', 'chr5_GL383530v1_alt', 'chr5_GL383531v1_alt', 'chr5_GL383532v1_alt', 'chr5_GL949742v1_alt', 'chr5_KI270791v1_alt', 'chr5_KI270792v1_alt', 'chr5_KI270793v1_alt', 'chr5_KI270794v1_alt', 'chr5_KI270795v1_alt', 'chr5_KI270796v1_alt', 'chr5_KI270897v1_alt', 'chr5_KI270898v1_alt', 'chr6', 'chr6_GL000250v2_alt', 'chr6_GL000251v2_alt', 'chr6_GL000252v2_alt', 'chr6_GL000253v2_alt', 'chr6_GL000254v2_alt', 'chr6_GL000255v2_alt', 'chr6_GL000256v2_alt', 'chr6_GL383533v1_alt', 'chr6_KB021644v2_alt', 'chr6_KI270758v1_alt', 'chr6_KI270797v1_alt', 'chr6_KI270798v1_alt', 'chr6_KI270799v1_alt', 'chr6_KI270800v1_alt', 'chr6_KI270801v1_alt', 'chr6_KI270802v1_alt', 'chr8', 'chr8_KI270810v1_alt', 'chr8_KI270811v1_alt', 'chr8_KI270812v1_alt', 'chr8_KI270813v1_alt', 'chr8_KI270814v1_alt', 'chr8_KI270815v1_alt', 'chr8_KI270816v1_alt', 'chr8_KI270817v1_alt', 'chr8_KI270818v1_alt', 'chr8_KI270819v1_alt', 'chr8_KI270820v1_alt', 'chr8_KI270821v1_alt', 'chr8_KI270822v1_alt', 'chr8_KI270900v1_alt', 'chr8_KI270901v1_alt', 'chr8_KI270926v1_alt']\n",
    "parts = [part1, part2, part3]\n",
    "\n",
    "cell_types = [\"MCF-7\", \"K562\", \"GM12878\", \"HepG2\", \"HEK293\", \"A549\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45356b86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celltype: K562\n",
      "fold: 0\n",
      "TF: ZBTB33, length: 140590\n",
      "Found 2 matrices for ZBTB33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:341: UserWarning: The handling of sequences with length < 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length < 101 is currently a placeholder and must be updated.\")\n",
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:345: UserWarning: The handling of sequences with length > 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length > 101 is currently a placeholder and must be updated.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: CTCF, length: 142427\n",
      "Found 6 matrices for CTCF\n",
      "TF: Egr-1, length: 143626\n",
      "Found 4 matrices for Egr-1\n",
      "TF: MAZ_(ab85725), length: 141590\n",
      "Found 2 matrices for MAZ_(ab85725)\n",
      "TF: MafK_(ab50322), length: 143553\n",
      "Found 4 matrices for MafK_(ab50322)\n",
      "TF: MafF_(M8194), length: 145054\n",
      "Found 4 matrices for MafF_(M8194)\n",
      "TF: Max, length: 141681\n",
      "Found 4 matrices for Max\n",
      "TF: YY1_(SC-281), length: 140889\n",
      "Found 2 matrices for YY1_(SC-281)\n",
      "TF: TBP, length: 141353\n",
      "No matrices found for TBP\n",
      "TF: ATF3, length: 140410\n",
      "Found 2 matrices for ATF3\n",
      "TF: JunD, length: 142191\n",
      "Found 5 matrices for JunD\n",
      "TF: RFX5_(200-401-194), length: 140525\n",
      "Found 3 matrices for RFX5_(200-401-194)\n",
      "TF: SRF, length: 140553\n",
      "Found 3 matrices for SRF\n",
      "TF: ATF1_(06-325), length: 140929\n",
      "No matrices found for ATF1_(06-325)\n",
      "TF: SIX5, length: 140516\n",
      "No matrices found for SIX5\n",
      "TF: SP1, length: 140546\n",
      "Found 5 matrices for SP1\n",
      "TF: NF-YA, length: 140516\n",
      "Found 4 matrices for NF-YA\n",
      "TF: NF-YB, length: 141307\n",
      "Found 3 matrices for NF-YB\n",
      "TF: USF-1, length: 141822\n",
      "No matrices found for USF-1\n",
      "TF: Znf143_(16618-1-AP), length: 141996\n",
      "Found 1 matrices for Znf143_(16618-1-AP)\n",
      "TF: ELF1_(SC-631), length: 141962\n",
      "Found 4 matrices for ELF1_(SC-631)\n",
      "TF: TEAD4_(SC-101184), length: 142006\n",
      "Found 3 matrices for TEAD4_(SC-101184)\n",
      "TF: CEBPB_(SC-150), length: 142646\n",
      "Found 4 matrices for CEBPB_(SC-150)\n",
      "TF: FOSL1_(SC-183), length: 140804\n",
      "Found 3 matrices for FOSL1_(SC-183)\n",
      "TF: ZNF274, length: 140525\n",
      "Found 2 matrices for ZNF274\n",
      "TF: SETDB1, length: 141464\n",
      "No matrices found for SETDB1\n",
      "TF: ETS1, length: 140672\n",
      "Found 3 matrices for ETS1\n",
      "TF: ZBTB7A_(SC-34508), length: 141698\n",
      "Found 3 matrices for ZBTB7A_(SC-34508)\n",
      "TF: NR2F2_(SC-271940), length: 141113\n",
      "Found 2 matrices for NR2F2_(SC-271940)\n",
      "TF: MEF2A, length: 140672\n",
      "Found 5 matrices for MEF2A\n",
      "TF: STAT5A_(SC-74442), length: 140714\n",
      "No matrices found for STAT5A_(SC-74442)\n",
      "TF: Nrf1, length: 140523\n",
      "Found 1 matrices for Nrf1\n",
      "TF: Mxi1_(AF4185), length: 140539\n",
      "Found 3 matrices for Mxi1_(AF4185)\n",
      "TF: ELK1_(1277-1), length: 140420\n",
      "Found 3 matrices for ELK1_(1277-1)\n",
      "TF: USF2, length: 140485\n",
      "Found 5 matrices for USF2\n",
      "TF: Bach1_(sc-14700), length: 140658\n",
      "Found 2 matrices for Bach1_(sc-14700)\n",
      "Only one class present for ZBTB33\n",
      "Only one class present for Egr-1\n",
      "Only one class present for MAZ_(ab85725)\n",
      "Only one class present for MafK_(ab50322)\n",
      "Only one class present for MafF_(M8194)\n",
      "Only one class present for Max\n",
      "Only one class present for YY1_(SC-281)\n",
      "Only one class present for ATF3\n",
      "Only one class present for JunD\n",
      "Only one class present for RFX5_(200-401-194)\n",
      "Only one class present for SRF\n",
      "Only one class present for SP1\n",
      "Only one class present for NF-YA\n",
      "Only one class present for NF-YB\n",
      "Only one class present for Znf143_(16618-1-AP)\n",
      "Only one class present for ELF1_(SC-631)\n",
      "Only one class present for TEAD4_(SC-101184)\n",
      "Only one class present for CEBPB_(SC-150)\n",
      "Only one class present for FOSL1_(SC-183)\n",
      "Only one class present for ZNF274\n",
      "Only one class present for ETS1\n",
      "Only one class present for ZBTB7A_(SC-34508)\n",
      "Only one class present for NR2F2_(SC-271940)\n",
      "Only one class present for MEF2A\n",
      "Only one class present for Nrf1\n",
      "Only one class present for Mxi1_(AF4185)\n",
      "Only one class present for ELK1_(1277-1)\n",
      "Only one class present for USF2\n",
      "Only one class present for Bach1_(sc-14700)\n",
      "fold: 1\n",
      "TF: ZBTB33, length: 160081\n",
      "Found 2 matrices for ZBTB33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:345: UserWarning: The handling of sequences with length > 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length > 101 is currently a placeholder and must be updated.\")\n",
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:341: UserWarning: The handling of sequences with length < 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length < 101 is currently a placeholder and must be updated.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: CTCF, length: 160804\n",
      "Found 6 matrices for CTCF\n",
      "TF: Egr-1, length: 162892\n",
      "Found 4 matrices for Egr-1\n",
      "TF: MAZ_(ab85725), length: 160655\n",
      "Found 2 matrices for MAZ_(ab85725)\n",
      "TF: MafK_(ab50322), length: 162611\n",
      "Found 4 matrices for MafK_(ab50322)\n",
      "TF: MafF_(M8194), length: 163975\n",
      "Found 4 matrices for MafF_(M8194)\n",
      "TF: Max, length: 160849\n",
      "Found 4 matrices for Max\n",
      "TF: YY1_(SC-281), length: 160173\n",
      "Found 2 matrices for YY1_(SC-281)\n",
      "TF: TBP, length: 160593\n",
      "No matrices found for TBP\n",
      "TF: ATF3, length: 159967\n",
      "Found 2 matrices for ATF3\n",
      "TF: JunD, length: 161231\n",
      "Found 5 matrices for JunD\n",
      "TF: RFX5_(200-401-194), length: 160038\n",
      "Found 3 matrices for RFX5_(200-401-194)\n",
      "TF: SRF, length: 160033\n",
      "Found 3 matrices for SRF\n",
      "TF: ATF1_(06-325), length: 160221\n",
      "No matrices found for ATF1_(06-325)\n",
      "TF: SIX5, length: 159981\n",
      "No matrices found for SIX5\n",
      "TF: SP1, length: 159975\n",
      "Found 5 matrices for SP1\n",
      "TF: NF-YA, length: 159951\n",
      "Found 4 matrices for NF-YA\n",
      "TF: NF-YB, length: 160466\n",
      "Found 3 matrices for NF-YB\n",
      "TF: USF-1, length: 161243\n",
      "No matrices found for USF-1\n",
      "TF: Znf143_(16618-1-AP), length: 161246\n",
      "Found 1 matrices for Znf143_(16618-1-AP)\n",
      "TF: ELF1_(SC-631), length: 161117\n",
      "Found 4 matrices for ELF1_(SC-631)\n",
      "TF: TEAD4_(SC-101184), length: 160903\n",
      "Found 3 matrices for TEAD4_(SC-101184)\n",
      "TF: CEBPB_(SC-150), length: 161907\n",
      "Found 4 matrices for CEBPB_(SC-150)\n",
      "TF: FOSL1_(SC-183), length: 160230\n",
      "Found 3 matrices for FOSL1_(SC-183)\n",
      "TF: ZNF274, length: 159950\n",
      "Found 2 matrices for ZNF274\n",
      "TF: SETDB1, length: 160956\n",
      "No matrices found for SETDB1\n",
      "TF: ETS1, length: 160221\n",
      "Found 3 matrices for ETS1\n",
      "TF: ZBTB7A_(SC-34508), length: 160952\n",
      "Found 3 matrices for ZBTB7A_(SC-34508)\n",
      "TF: NR2F2_(SC-271940), length: 160428\n",
      "Found 2 matrices for NR2F2_(SC-271940)\n",
      "TF: MEF2A, length: 160177\n",
      "Found 5 matrices for MEF2A\n",
      "TF: STAT5A_(SC-74442), length: 160020\n",
      "No matrices found for STAT5A_(SC-74442)\n",
      "TF: Nrf1, length: 159972\n",
      "Found 1 matrices for Nrf1\n",
      "TF: Mxi1_(AF4185), length: 160027\n",
      "Found 3 matrices for Mxi1_(AF4185)\n",
      "TF: ELK1_(1277-1), length: 159988\n",
      "Found 3 matrices for ELK1_(1277-1)\n",
      "TF: USF2, length: 160031\n",
      "Found 5 matrices for USF2\n",
      "TF: Bach1_(sc-14700), length: 160150\n",
      "Found 2 matrices for Bach1_(sc-14700)\n",
      "Unexpected error for ZBTB33: 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for Egr-1: 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for MAZ_(ab85725): 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for MafK_(ab50322): 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for MafF_(M8194): 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for Max: 'NoneType' object has no attribute 'append'\n",
      "Only one class present for YY1_(SC-281)\n",
      "Only one class present for ATF3\n",
      "Only one class present for JunD\n",
      "Only one class present for RFX5_(200-401-194)\n",
      "Only one class present for SRF\n",
      "Only one class present for SP1\n",
      "Only one class present for NF-YA\n",
      "Only one class present for NF-YB\n",
      "Only one class present for Znf143_(16618-1-AP)\n",
      "Only one class present for ELF1_(SC-631)\n",
      "Only one class present for TEAD4_(SC-101184)\n",
      "Only one class present for CEBPB_(SC-150)\n",
      "Only one class present for FOSL1_(SC-183)\n",
      "Only one class present for ZNF274\n",
      "Only one class present for ETS1\n",
      "Only one class present for ZBTB7A_(SC-34508)\n",
      "Only one class present for NR2F2_(SC-271940)\n",
      "Only one class present for MEF2A\n",
      "Only one class present for Nrf1\n",
      "Only one class present for Mxi1_(AF4185)\n",
      "Only one class present for ELK1_(1277-1)\n",
      "Only one class present for USF2\n",
      "Only one class present for Bach1_(sc-14700)\n",
      "fold: 2\n",
      "TF: ZBTB33, length: 201260\n",
      "Found 2 matrices for ZBTB33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:341: UserWarning: The handling of sequences with length < 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length < 101 is currently a placeholder and must be updated.\")\n",
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:345: UserWarning: The handling of sequences with length > 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length > 101 is currently a placeholder and must be updated.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: CTCF, length: 202087\n",
      "Found 6 matrices for CTCF\n",
      "TF: Egr-1, length: 204572\n",
      "Found 4 matrices for Egr-1\n",
      "TF: MAZ_(ab85725), length: 201783\n",
      "Found 2 matrices for MAZ_(ab85725)\n",
      "TF: MafK_(ab50322), length: 204984\n",
      "Found 4 matrices for MafK_(ab50322)\n",
      "TF: MafF_(M8194), length: 206932\n",
      "Found 4 matrices for MafF_(M8194)\n",
      "TF: Max, length: 202033\n",
      "Found 4 matrices for Max\n",
      "TF: YY1_(SC-281), length: 201310\n",
      "Found 2 matrices for YY1_(SC-281)\n",
      "TF: TBP, length: 201865\n",
      "No matrices found for TBP\n",
      "TF: ATF3, length: 201072\n",
      "Found 2 matrices for ATF3\n",
      "TF: JunD, length: 202594\n",
      "Found 5 matrices for JunD\n",
      "TF: RFX5_(200-401-194), length: 201184\n",
      "Found 3 matrices for RFX5_(200-401-194)\n",
      "TF: SRF, length: 201183\n",
      "Found 3 matrices for SRF\n",
      "TF: ATF1_(06-325), length: 201370\n",
      "No matrices found for ATF1_(06-325)\n",
      "TF: SIX5, length: 201090\n",
      "No matrices found for SIX5\n",
      "TF: SP1, length: 201113\n",
      "Found 5 matrices for SP1\n",
      "TF: NF-YA, length: 201157\n",
      "Found 4 matrices for NF-YA\n",
      "TF: NF-YB, length: 201927\n",
      "Found 3 matrices for NF-YB\n",
      "TF: USF-1, length: 202638\n",
      "No matrices found for USF-1\n",
      "TF: Znf143_(16618-1-AP), length: 202208\n",
      "Found 1 matrices for Znf143_(16618-1-AP)\n",
      "TF: ELF1_(SC-631), length: 202379\n",
      "Found 4 matrices for ELF1_(SC-631)\n",
      "TF: TEAD4_(SC-101184), length: 202346\n",
      "Found 3 matrices for TEAD4_(SC-101184)\n",
      "TF: CEBPB_(SC-150), length: 203672\n",
      "Found 4 matrices for CEBPB_(SC-150)\n",
      "TF: FOSL1_(SC-183), length: 201360\n",
      "Found 3 matrices for FOSL1_(SC-183)\n",
      "TF: ZNF274, length: 201127\n",
      "Found 2 matrices for ZNF274\n",
      "TF: SETDB1, length: 202192\n",
      "No matrices found for SETDB1\n",
      "TF: ETS1, length: 201307\n",
      "Found 3 matrices for ETS1\n",
      "TF: ZBTB7A_(SC-34508), length: 202098\n",
      "Found 3 matrices for ZBTB7A_(SC-34508)\n",
      "TF: NR2F2_(SC-271940), length: 201595\n",
      "Found 2 matrices for NR2F2_(SC-271940)\n",
      "TF: MEF2A, length: 201390\n",
      "Found 5 matrices for MEF2A\n",
      "TF: STAT5A_(SC-74442), length: 201193\n",
      "No matrices found for STAT5A_(SC-74442)\n",
      "TF: Nrf1, length: 201091\n",
      "Found 1 matrices for Nrf1\n",
      "TF: Mxi1_(AF4185), length: 201160\n",
      "Found 3 matrices for Mxi1_(AF4185)\n",
      "TF: ELK1_(1277-1), length: 201089\n",
      "Found 3 matrices for ELK1_(1277-1)\n",
      "TF: USF2, length: 201132\n",
      "Found 5 matrices for USF2\n",
      "TF: Bach1_(sc-14700), length: 201360\n",
      "Found 2 matrices for Bach1_(sc-14700)\n",
      "Unexpected error for ZBTB33: 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for Egr-1: 'NoneType' object has no attribute 'append'\n",
      "Only one class present for MAZ_(ab85725)\n",
      "Unexpected error for MafK_(ab50322): 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for MafF_(M8194): 'NoneType' object has no attribute 'append'\n",
      "Only one class present for Max\n",
      "Only one class present for YY1_(SC-281)\n",
      "Only one class present for ATF3\n",
      "Unexpected error for JunD: 'NoneType' object has no attribute 'append'\n",
      "Only one class present for RFX5_(200-401-194)\n",
      "Only one class present for SRF\n",
      "Only one class present for SP1\n",
      "Only one class present for NF-YA\n",
      "Only one class present for NF-YB\n",
      "Unexpected error for Znf143_(16618-1-AP): 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for ELF1_(SC-631): 'NoneType' object has no attribute 'append'\n",
      "Unexpected error for TEAD4_(SC-101184): 'NoneType' object has no attribute 'append'\n",
      "Only one class present for CEBPB_(SC-150)\n",
      "Unexpected error for FOSL1_(SC-183): 'NoneType' object has no attribute 'append'\n",
      "Only one class present for ZNF274\n",
      "Only one class present for ETS1\n",
      "Unexpected error for ZBTB7A_(SC-34508): 'NoneType' object has no attribute 'append'\n",
      "Only one class present for NR2F2_(SC-271940)\n",
      "Only one class present for MEF2A\n",
      "Only one class present for Nrf1\n",
      "Only one class present for Mxi1_(AF4185)\n",
      "Only one class present for ELK1_(1277-1)\n",
      "Only one class present for USF2\n",
      "Only one class present for Bach1_(sc-14700)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 114\u001b[39m\n\u001b[32m    107\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calculating accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    113\u001b[39m df = pd.DataFrame.from_dict(\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     \u001b[43m{\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAUROC_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mAUROC_scores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m,\n\u001b[32m    115\u001b[39m     orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    116\u001b[39m     columns=[\u001b[33m\"\u001b[39m\u001b[33mAUROC_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    117\u001b[39m )\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# # Ensure the output folder exists\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# os.makedirs(out_folder, exist_ok=True)\u001b[39;00m\n\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# # Write the dataframe to a CSV file in the specified output folder\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# df.to_csv(os.path.join(out_folder, f\"{celltype}.csv\"), index=True)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    107\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calculating accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    108\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    113\u001b[39m df = pd.DataFrame.from_dict(\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m     {tf: \u001b[43mAUROC_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tf \u001b[38;5;129;01min\u001b[39;00m AUROC_scores.keys()},\n\u001b[32m    115\u001b[39m     orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    116\u001b[39m     columns=[\u001b[33m\"\u001b[39m\u001b[33mAUROC_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    117\u001b[39m )\n\u001b[32m    118\u001b[39m \u001b[38;5;66;03m# # Ensure the output folder exists\u001b[39;00m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# os.makedirs(out_folder, exist_ok=True)\u001b[39;00m\n\u001b[32m    120\u001b[39m \n\u001b[32m    121\u001b[39m \u001b[38;5;66;03m# # Write the dataframe to a CSV file in the specified output folder\u001b[39;00m\n\u001b[32m    122\u001b[39m \u001b[38;5;66;03m# df.to_csv(os.path.join(out_folder, f\"{celltype}.csv\"), index=True)\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "cell_types = [\"K562\"]\n",
    "AUROC_scores = {}\n",
    "accuracy_scores = {}\n",
    "for celltype in cell_types:\n",
    "    print(\"celltype: \" + celltype)\n",
    "    tf_auroc_scores = {}\n",
    "    tf_accuracy_scores = {}\n",
    "    for fold in range(3):\n",
    "        print(\"fold: \" + str(fold))\n",
    "        file = h5torch.File(data_folder+celltype+\".h5t\", 'r')\n",
    "        TF_list = [TF.decode() for TF in file[\"0/prot_names\"][:]]\n",
    "        TF_list.remove(\"ATAC_peak\")\n",
    "\n",
    "        results = {}\n",
    "        true_vals = {}\n",
    "        for TF in TF_list:\n",
    "            dataset = HQ_dataset(file, TF, subset=parts[fold])\n",
    "            print(f\"TF: {TF}, length: {dataset.__len__()}\")\n",
    "            matrices = jaspar_dict[TF]\n",
    "            true_vals[TF] = []\n",
    "            if matrices == []:\n",
    "                print(f\"No matrices found for {TF}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Found {len(matrices)} matrices for {TF}\")\n",
    "                for i in range(30): #! range(dataset.__len__()): \n",
    "                    # Scan each PWM on both strands\n",
    "                    seq = Seq(\"\".join([dataset.rev_mapping[i] for i in dataset.__getitem__(i)[\"1/DNA_regions\"]]))\n",
    "                    true_vals[TF].append(dataset.__getitem__(i)[\"central\"])\n",
    "                    \n",
    "                    best_score = []\n",
    "                    for mid in matrices:\n",
    "                        pssm = motif_objects[mid] \n",
    "                        # Score forward strand\n",
    "                        scores_fwd = pssm.calculate(seq)\n",
    "                        max_fwd = np.nanmax(scores_fwd) if len(scores_fwd)>0 else float('-inf')\n",
    "                        # Score reverse complement\n",
    "                        rc_seq = str(Seq(seq).reverse_complement())\n",
    "                        scores_rev = pssm.calculate(rc_seq)\n",
    "                        max_rev = np.nanmax(scores_rev) if len(scores_rev)>0 else float('-inf')\n",
    "                        # Take the best (highest) score\n",
    "                        best_score.append(np.nanmax([max_fwd, max_rev]))\n",
    "\n",
    "                    results.setdefault(TF, []).append(np.nanmax(best_score))\n",
    "\n",
    "\n",
    "        for TF, scores in results.items():\n",
    "            labels = true_vals[TF]\n",
    "            scores = np.array(scores)\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            if len(scores) != len(labels):\n",
    "                print(f\"Length mismatch for {TF}: {len(scores)} vs {len(labels)}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(np.unique(labels)) < 2:\n",
    "                print(f\"Only one class present for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(scores) == 0:\n",
    "                print(f\"No scores for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(labels) == 0:\n",
    "                print(f\"No labels for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if np.isnan(scores).any():\n",
    "                print(f\"NaN values in scores for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if np.isnan(labels).any():\n",
    "                print(f\"NaN values in labels for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(np.unique(labels)) == 1:\n",
    "                print(f\"Only one class present in labels for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            \n",
    "            # Calculate AUROC score\n",
    "            try:\n",
    "                auc = roc_auc_score(labels, scores)\n",
    "                AUROC_scores.setdefault(TF, []).append(auc)\n",
    "            except ValueError as e:\n",
    "                print(f\"ValueError for {TF}: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error for {TF}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate accuracy score with threshold at 0.8 * max_score\n",
    "            try:\n",
    "                max_score = np.max(scores)\n",
    "                threshold = 0.8 * max_score #! important setting for accuracy\n",
    "                predictions = (scores > threshold).astype(int)\n",
    "                acc = accuracy_score(labels, predictions)\n",
    "                accuracy_scores.setdefault(TF, []).append(acc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating accuracy for {TF}: {e}\")\n",
    "                continue\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict(\n",
    "        {tf: AUROC_scores[tf] + accuracy_scores[tf] for tf in AUROC_scores.keys()},\n",
    "        orient='index',\n",
    "        columns=[\"AUROC_1\", \"AUROC_2\", \"AUROC_3\", \"Accuracy_1\", \"Accuracy_2\", \"Accuracy_3\"]\n",
    "    )\n",
    "    # # Ensure the output folder exists\n",
    "    # os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # # Write the dataframe to a CSV file in the specified output folder\n",
    "    # df.to_csv(os.path.join(out_folder, f\"{celltype}.csv\"), index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5dd02427",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m df = pd.DataFrame.from_dict(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m        \u001b[43m{\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAUROC_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mAUROC_scores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m,\n\u001b[32m      3\u001b[39m        orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m        columns=[\u001b[33m\"\u001b[39m\u001b[33mAUROC_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m    )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      1\u001b[39m df = pd.DataFrame.from_dict(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m        {tf: \u001b[43mAUROC_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tf \u001b[38;5;129;01min\u001b[39;00m AUROC_scores.keys()},\n\u001b[32m      3\u001b[39m        orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      4\u001b[39m        columns=[\u001b[33m\"\u001b[39m\u001b[33mAUROC_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      5\u001b[39m    )\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    " df = pd.DataFrame.from_dict(\n",
    "        {tf: AUROC_scores[tf] + accuracy_scores[tf] for tf in AUROC_scores.keys()},\n",
    "        orient='index',\n",
    "        columns=[\"AUROC_1\", \"AUROC_2\", \"AUROC_3\", \"Accuracy_1\", \"Accuracy_2\", \"Accuracy_3\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "755f9227",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/anaconda3/envs/Negs/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe24bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a6a5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764a46a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "celltype: K562\n",
      "fold: 2\n",
      "TF: ZBTB33, length: 201260\n",
      "Found 2 matrices for ZBTB33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:335: UserWarning: The handling of sequences with length < 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length < 101 is currently a placeholder and must be updated.\")\n",
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:339: UserWarning: The handling of sequences with length > 101 is currently a placeholder and must be updated.\n",
      "  warnings.warn(\"The handling of sequences with length > 101 is currently a placeholder and must be updated.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: CTCF, length: 202087\n",
      "Found 6 matrices for CTCF\n",
      "TF: Egr-1, length: 204572\n",
      "Found 4 matrices for Egr-1\n",
      "TF: MAZ_(ab85725), length: 201783\n",
      "Found 2 matrices for MAZ_(ab85725)\n",
      "TF: MafK_(ab50322), length: 204984\n",
      "Found 4 matrices for MafK_(ab50322)\n",
      "TF: MafF_(M8194), length: 206932\n",
      "Found 4 matrices for MafF_(M8194)\n",
      "TF: Max, length: 202033\n",
      "Found 4 matrices for Max\n",
      "TF: YY1_(SC-281), length: 201310\n",
      "Found 2 matrices for YY1_(SC-281)\n",
      "TF: TBP, length: 201865\n",
      "No matrices found for TBP\n",
      "TF: ATF3, length: 201072\n",
      "Found 2 matrices for ATF3\n",
      "TF: JunD, length: 202594\n",
      "Found 5 matrices for JunD\n",
      "TF: RFX5_(200-401-194), length: 201184\n",
      "Found 3 matrices for RFX5_(200-401-194)\n",
      "TF: SRF, length: 201183\n",
      "Found 3 matrices for SRF\n",
      "TF: ATF1_(06-325), length: 201370\n",
      "No matrices found for ATF1_(06-325)\n",
      "TF: SIX5, length: 201090\n",
      "No matrices found for SIX5\n",
      "TF: SP1, length: 201113\n",
      "Found 5 matrices for SP1\n",
      "TF: NF-YA, length: 201157\n",
      "Found 4 matrices for NF-YA\n",
      "TF: NF-YB, length: 201927\n",
      "Found 3 matrices for NF-YB\n",
      "TF: USF-1, length: 202638\n",
      "No matrices found for USF-1\n",
      "TF: Znf143_(16618-1-AP), length: 202208\n",
      "Found 1 matrices for Znf143_(16618-1-AP)\n",
      "TF: ELF1_(SC-631), length: 202379\n",
      "Found 4 matrices for ELF1_(SC-631)\n",
      "TF: TEAD4_(SC-101184), length: 202346\n",
      "Found 3 matrices for TEAD4_(SC-101184)\n",
      "TF: CEBPB_(SC-150), length: 203672\n",
      "Found 4 matrices for CEBPB_(SC-150)\n",
      "TF: FOSL1_(SC-183), length: 201360\n",
      "Found 3 matrices for FOSL1_(SC-183)\n",
      "TF: ZNF274, length: 201127\n",
      "Found 2 matrices for ZNF274\n",
      "TF: SETDB1, length: 202192\n",
      "No matrices found for SETDB1\n",
      "TF: ETS1, length: 201307\n",
      "Found 3 matrices for ETS1\n",
      "TF: ZBTB7A_(SC-34508), length: 202098\n",
      "Found 3 matrices for ZBTB7A_(SC-34508)\n",
      "TF: NR2F2_(SC-271940), length: 201595\n",
      "Found 2 matrices for NR2F2_(SC-271940)\n",
      "TF: MEF2A, length: 201390\n",
      "Found 5 matrices for MEF2A\n",
      "TF: STAT5A_(SC-74442), length: 201193\n",
      "No matrices found for STAT5A_(SC-74442)\n",
      "TF: Nrf1, length: 201091\n",
      "Found 1 matrices for Nrf1\n",
      "TF: Mxi1_(AF4185), length: 201160\n",
      "Found 3 matrices for Mxi1_(AF4185)\n",
      "TF: ELK1_(1277-1), length: 201089\n",
      "Found 3 matrices for ELK1_(1277-1)\n",
      "TF: USF2, length: 201132\n",
      "Found 5 matrices for USF2\n",
      "TF: Bach1_(sc-14700), length: 201360\n",
      "Found 2 matrices for Bach1_(sc-14700)\n",
      "NaN values in scores for ZBTB33\n",
      "NaN values in scores for CTCF\n",
      "NaN values in scores for Egr-1\n",
      "NaN values in scores for MAZ_(ab85725)\n",
      "NaN values in scores for MafK_(ab50322)\n",
      "NaN values in scores for MafF_(M8194)\n",
      "NaN values in scores for Max\n",
      "NaN values in scores for YY1_(SC-281)\n",
      "NaN values in scores for ATF3\n",
      "NaN values in scores for JunD\n",
      "NaN values in scores for RFX5_(200-401-194)\n",
      "NaN values in scores for SRF\n",
      "NaN values in scores for SP1\n",
      "NaN values in scores for NF-YA\n",
      "NaN values in scores for NF-YB\n",
      "NaN values in scores for Znf143_(16618-1-AP)\n",
      "NaN values in scores for ELF1_(SC-631)\n",
      "NaN values in scores for TEAD4_(SC-101184)\n",
      "NaN values in scores for CEBPB_(SC-150)\n",
      "NaN values in scores for FOSL1_(SC-183)\n",
      "NaN values in scores for ZNF274\n",
      "NaN values in scores for ETS1\n",
      "NaN values in scores for ZBTB7A_(SC-34508)\n",
      "NaN values in scores for NR2F2_(SC-271940)\n",
      "NaN values in scores for MEF2A\n",
      "NaN values in scores for Nrf1\n",
      "NaN values in scores for Mxi1_(AF4185)\n",
      "NaN values in scores for ELK1_(1277-1)\n",
      "NaN values in scores for USF2\n",
      "NaN values in scores for Bach1_(sc-14700)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'NoneType' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 115\u001b[39m\n\u001b[32m    108\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calculating accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    114\u001b[39m df = pd.DataFrame.from_dict(\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[43m{\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mAUROC_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mAUROC_scores\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m}\u001b[49m,\n\u001b[32m    116\u001b[39m     orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    117\u001b[39m     columns=[\u001b[33m\"\u001b[39m\u001b[33mAUROC_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    118\u001b[39m )\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Ensure the output folder exists\u001b[39;00m\n\u001b[32m    120\u001b[39m os.makedirs(out_folder, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36m<dictcomp>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m    108\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calculating accuracy for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    109\u001b[39m             \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    114\u001b[39m df = pd.DataFrame.from_dict(\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     {tf: \u001b[43mAUROC_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43maccuracy_scores\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtf\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m tf \u001b[38;5;129;01min\u001b[39;00m AUROC_scores.keys()},\n\u001b[32m    116\u001b[39m     orient=\u001b[33m'\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    117\u001b[39m     columns=[\u001b[33m\"\u001b[39m\u001b[33mAUROC_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAUROC_3\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_1\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_2\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mAccuracy_3\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    118\u001b[39m )\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# Ensure the output folder exists\u001b[39;00m\n\u001b[32m    120\u001b[39m os.makedirs(out_folder, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'NoneType' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "\n",
    "AUROC_scores = {}\n",
    "accuracy_scores = {}\n",
    "for celltype in cell_types:\n",
    "    print(\"celltype: \" + celltype)\n",
    "    tf_auroc_scores = {}\n",
    "    tf_accuracy_scores = {}\n",
    "    for fold in [2]:\n",
    "        print(\"fold: \" + str(fold))\n",
    "        file = h5torch.File(data_folder+celltype+\".h5t\", 'r')\n",
    "        TF_list = [TF.decode() for TF in file[\"0/prot_names\"][:]]\n",
    "        TF_list.remove(\"ATAC_peak\")\n",
    "\n",
    "        results = {}\n",
    "        true_vals = {}\n",
    "        for TF in TF_list:\n",
    "            dataset = HQ_dataset(file, TF, subset=parts[fold])\n",
    "            print(f\"TF: {TF}, length: {dataset.__len__()}\")\n",
    "            matrices = jaspar_dict[TF]\n",
    "            true_vals[TF] = []\n",
    "            if matrices == []:\n",
    "                print(f\"No matrices found for {TF}\")\n",
    "                continue\n",
    "            else:\n",
    "                print(f\"Found {len(matrices)} matrices for {TF}\")\n",
    "                for i in range(30): # !range(dataset.__len__()): \n",
    "                    # Scan each PWM on both strands\n",
    "                    seq = Seq(\"\".join([dataset.rev_mapping[i] for i in dataset.__getitem__(i)[\"1/DNA_regions\"]]))\n",
    "                    true_vals[TF].append(dataset.__getitem__(i)[\"central\"])\n",
    "                    \n",
    "                    best_score = []\n",
    "                    for mid in matrices:\n",
    "                        pssm = motif_objects[mid] \n",
    "                        # Score forward strand\n",
    "                        scores_fwd = pssm.calculate(seq)\n",
    "                        max_fwd = np.nanmax(scores_fwd) if len(scores_fwd)>0 else float('-inf')\n",
    "                        # Score reverse complement\n",
    "                        rc_seq = str(Seq(seq).reverse_complement())\n",
    "                        scores_rev = pssm.calculate(rc_seq)\n",
    "                        max_rev = np.nanmax(scores_rev) if len(scores_rev)>0 else float('-inf')\n",
    "                        # Take the best (highest) score\n",
    "                        best_score.append(np.nanmax([max_fwd, max_rev]))\n",
    "\n",
    "                    results.setdefault(TF, []).append(np.nanmax(best_score))\n",
    "\n",
    "\n",
    "        for TF, scores in results.items():\n",
    "            labels = true_vals[TF]\n",
    "            scores = np.array(scores)\n",
    "            labels = np.array(labels)\n",
    "            \n",
    "            if len(scores) != len(labels):\n",
    "                print(f\"Length mismatch for {TF}: {len(scores)} vs {len(labels)}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(np.unique(labels)) < 2:\n",
    "                print(f\"Only one class present for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(scores) == 0:\n",
    "                print(f\"No scores for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(labels) == 0:\n",
    "                print(f\"No labels for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if np.isnan(scores).any():\n",
    "                print(f\"NaN values in scores for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if np.isnan(labels).any():\n",
    "                print(f\"NaN values in labels for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            if len(np.unique(labels)) == 1:\n",
    "                print(f\"Only one class present in labels for {TF}\")\n",
    "                accuracy_scores[TF] = None\n",
    "                AUROC_scores[TF] = None\n",
    "                continue\n",
    "            \n",
    "            # Calculate AUROC score\n",
    "            try:\n",
    "                auc = roc_auc_score(labels, scores)\n",
    "                AUROC_scores.setdefault(TF, []).append(auc)\n",
    "            except ValueError as e:\n",
    "                print(f\"ValueError for {TF}: {e}\")\n",
    "                continue\n",
    "            except Exception as e:\n",
    "                print(f\"Unexpected error for {TF}: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # Calculate accuracy score with threshold at 0.8 * max_score\n",
    "            try:\n",
    "                max_score = np.max(scores)\n",
    "                threshold = 0.8 * max_score #! important setting for accuracy\n",
    "                predictions = (scores > threshold).astype(int)\n",
    "                acc = accuracy_score(labels, predictions)\n",
    "                accuracy_scores.setdefault(TF, []).append(acc)\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating accuracy for {TF}: {e}\")\n",
    "                continue\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "    df = pd.DataFrame.from_dict(\n",
    "        {tf: AUROC_scores[tf] + accuracy_scores[tf] for tf in AUROC_scores.keys()},\n",
    "        orient='index',\n",
    "        columns=[\"AUROC_1\", \"AUROC_2\", \"AUROC_3\", \"Accuracy_1\", \"Accuracy_2\", \"Accuracy_3\"]\n",
    "    )\n",
    "    # Ensure the output folder exists\n",
    "    os.makedirs(out_folder, exist_ok=True)\n",
    "\n",
    "    # Write the dataframe to a CSV file in the specified output folder\n",
    "    df.to_csv(os.path.join(out_folder, f\"{celltype}.csv\"), index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e9ef756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50996]\n"
     ]
    }
   ],
   "source": [
    "nan_index = np.where(np.isnan(scores))[0]\n",
    "print(nan_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "636f962f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/natant/Negatives/TFBS_negatives/TFBS_negatives/data.py:335: UserWarning: The handling of sequences with length < 101 is currently a placeholder and must be updated.\n",
      "  len = self.peak_ix_to_len[index]\n"
     ]
    }
   ],
   "source": [
    "i = nan_index[0]\n",
    "seq = Seq(\"\".join([dataset.rev_mapping[i] for i in dataset.__getitem__(i)[\"1/DNA_regions\"]]))\n",
    "\n",
    "                    \n",
    "best_score = []\n",
    "for mid in matrices:\n",
    "    pssm = motif_objects[mid] \n",
    "    # Score forward strand\n",
    "    scores_fwd = pssm.calculate(seq)\n",
    "    max_fwd = max(scores_fwd) if len(scores_fwd)>0 else float('-inf')\n",
    "    # Score reverse complement\n",
    "    rc_seq = str(Seq(seq).reverse_complement())\n",
    "    scores_rev = pssm.calculate(rc_seq)\n",
    "    max_rev = max(scores_rev) if len(scores_rev)>0 else float('-inf')\n",
    "    # Take the best (highest) score\n",
    "    best_score.append(max(max_fwd, max_rev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d1f03e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq('NNNNNNNNNNCCGAGGCCGATCCCCGCGCGCTGGCGGCACCGAGCGCCAAAGGC...GGG')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0dd8fff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([       nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "       -29.769154, -61.019722, -27.323347, -22.8349  , -60.41835 ,\n",
       "       -34.969124, -25.569622, -47.56085 , -33.935833, -36.582542,\n",
       "       -33.950127, -66.62186 , -34.096256, -51.98067 , -37.169518,\n",
       "       -54.50483 , -40.0637  , -37.329952, -51.703503, -57.415718,\n",
       "       -23.035275, -28.745142, -57.899597, -25.38091 , -35.641884,\n",
       "       -29.890713, -39.009197, -64.27578 , -35.522366, -44.1656  ,\n",
       "       -39.370632, -35.423027, -31.360575, -18.580858, -47.0214  ,\n",
       "       -39.444275, -43.338905, -45.236862, -57.837658, -27.233274,\n",
       "       -24.861732, -39.254246, -30.335196, -43.66073 , -45.687454,\n",
       "       -39.674862, -47.661777, -46.464046, -41.49976 , -39.82249 ,\n",
       "       -54.062218, -60.1692  , -47.417236, -37.987686, -45.812366,\n",
       "       -27.553675, -41.084927, -38.143185, -51.070667, -19.66264 ,\n",
       "       -30.621265, -30.335196, -41.59963 , -47.247765, -39.322803,\n",
       "       -56.91958 , -38.20478 , -53.706493, -31.976845, -43.631016,\n",
       "       -35.48299 , -21.03364 , -52.48376 , -25.806417, -45.47142 ,\n",
       "       -53.583775, -55.842056, -30.536718, -39.92697 , -44.086018,\n",
       "       -34.29191 , -14.614486, -68.317215], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1894c53d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(nan)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_fwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47c5f683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-11.070657)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "be634e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float32(-11.070657)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nanmax([max_fwd, max_rev])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Negs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
